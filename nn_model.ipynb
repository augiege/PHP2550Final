{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.create_features_utils import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import models, layers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import metrics\n",
    "from keras.models import load_model\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read match data with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/wimbledon_matches_with_feature.csv')\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "df['diff_rank'] = df['player_0_rank'] - df['player_1_rank']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = [\n",
    " 'diff_rank',\n",
    " 'diff_match_win_percent',\n",
    " 'diff_games_win_percent',\n",
    " 'diff_5_set_match_win_percent',\n",
    " 'diff_close_sets_percent',\n",
    " 'diff_match_win_percent_grass',\n",
    " 'diff_games_win_percent_grass',\n",
    " 'diff_5_set_match_win_percent_grass',\n",
    " 'diff_close_sets_percent_grass',\n",
    " 'diff_match_win_percent_52',\n",
    " 'diff_games_win_percent_52',\n",
    " 'diff_5_set_match_win_percent_52',\n",
    " 'diff_close_sets_percent_52',\n",
    " 'diff_match_win_percent_grass_60',\n",
    " 'diff_games_win_percent_grass_60',\n",
    " 'diff_5_set_match_win_percent_grass_60',\n",
    " 'diff_close_sets_percent_grass_60',\n",
    " 'diff_match_win_percent_hh',\n",
    " 'diff_games_win_percent_hh',\n",
    " 'diff_match_win_percent_grass_hh',\n",
    " 'diff_games_win_percent_grass_hh']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data intro Train (80 %) and Test (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df.outcome\n",
    "features = df[features_list]\n",
    "\n",
    "train_features, test_features, train_target, test_target = train_test_split(features, target, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the neural network. \n",
    "### Deatils\n",
    "    - Number of Layers: 3. (2 Hidden Layers)\n",
    "    - Number of Neuros in each layer: 64->32->1\n",
    "    - Activation relu->relu->sigmoid\n",
    "    - Stop if validation loss does not improve for 500 epochs\n",
    "    - Save the best model which gives the maximum validation accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(units=64, activation='relu', input_shape=(len(features.columns),)))\n",
    "network.add(layers.Dense(units=32, activation='relu'))\n",
    "network.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "network.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=500)\n",
    "mc = ModelCheckpoint('data/best_model.h5', monitor='val_loss', mode='min', verbose=2, save_best_only=True)\n",
    "\n",
    "history = network.fit(train_features, train_target, \n",
    "            epochs=1000, verbose=0, batch_size=128, \n",
    "            validation_data=(test_features, test_target), callbacks=[es, mc]) \n",
    "\n",
    "saved_model = load_model('data/best_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, train_acc = saved_model.evaluate(train_features, train_target, verbose=0)\n",
    "_, test_acc = saved_model.evaluate(test_features, test_target, verbose=0)\n",
    "\n",
    "print('Train Accuracy: %.3f, Test Accuracy: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph showing train/test loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Loss after each Epoch')\n",
    "plt.plot(history.epoch[::10], history.history['loss'][::10], label='Train')\n",
    "plt.plot(history.epoch[::10], history.history['val_loss'][::10], label='Test')\n",
    "plt.legend(['Train', 'Test'],loc='upper right', title='Sample', facecolor='white',fancybox=True)\n",
    "plt.xlabel('Loss')\n",
    "plt.ylabel('Epochs')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Accuracy after each Epoch')\n",
    "plt.plot(history.epoch[::10], history.history['acc'][::10], label='Train')\n",
    "plt.plot(history.epoch[::10], history.history['val_acc'][::10], label='Test')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Epochs')\n",
    "plt.legend(['Train', 'Test'], loc='upper left', title='Sample', facecolor='white', fancybox=True)\n",
    "\n",
    "\n",
    "plt.savefig('data/results/loss_acc.jpg', quality=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data classification report and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(test_target, saved_model.predict_classes(test_features)))\n",
    "print(confusion_matrix(test_target, saved_model.predict_classes(test_features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data classification report and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(train_target, saved_model.predict_classes(train_features)))\n",
    "print(confusion_matrix(train_target, saved_model.predict_classes(train_features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2019 Wimbledon Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019 = pd.read_csv('data/wimbledon_2019.csv')\n",
    "df_raw = pd.read_csv('data/mens/combined_raw_data.csv')\n",
    "\n",
    "df_2019['Date'] = '2019/07/07'\n",
    "df_2019['Surface'] = 'Grass'\n",
    "df_2019['diff_rank'] = df_2019['player_0_rank'] - df_2019['player_1_rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating features to make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_2019 = create_features(df_2019, df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Predictions\n",
    "    - Outcome 0 indicates player_0 will win and outcome 1 indicates player_1 will win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_16 = df_2019[features_list]\n",
    "\n",
    "df_2019['prediction'] = saved_model.predict_classes(features_16)\n",
    "df_2019['probability'] = 1 - np.abs(df_2019.prediction - saved_model.predict_proba(features_16).flatten())\n",
    "\n",
    "df_2019[['Round', 'player_0', 'player_1', 'prediction', 'probability']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_16"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
